# Book Recommendation System
```markdown
# Book Recommendation Web App [file:1][file:3]

A Flask-based book recommendation web application that combines content-based filtering (TF-IDF) and collaborative filtering (implicit ALS), with an MMR re-ranking step to balance relevance and diversity. [file:1][file:3]

---

### Features [file:1][file:3]

- Content-based search using TF-IDF over book titles, supporting keyword queries and similar-book lookup from a seed title. [file:1][file:3]  
- Collaborative filtering recommendations using an implicit ALS model trained on user–book rating data. [file:1][file:3]  
- Hybrid recommender that linearly combines content and collaborative scores and then applies MMR to encourage diverse suggestions. [file:1]  
- Dislike list stored in session so users can hide unwanted books from future hybrid recommendations. [file:1]  
- Simple web UI built with Jinja2 templates, including a main search form and a results page showing query metadata and recommendations. [file:1]

---

### Tech Stack [file:1][file:3]

- Backend framework: Flask. [file:1]  
- Data and math: pandas, NumPy, SciPy. [file:1][file:3]  
- Machine learning: scikit-learn (TF-IDF), implicit (ALS matrix factorization). [file:1][file:3]  
- Templates: Jinja2 HTML templates (`index.html`, `base.html`, `results.html`). [file:1]  
- Model and artifact persistence: joblib, pickle, NumPy binary files, and CSV. [file:1][file:3]

---

### Project Structure [file:1][file:3]

```
.
├── app.py           # Flask app and recommendation logic
├── train.py         # Offline training and artifact export
├── templates
│   ├── base.html    # Base layout
│   ├── index.html   # Main UI and forms
│   └── results.html # Result summary page
└── artifacts        # Generated by train.py
    ├── books.csv
    ├── tfidf_vectorizer.joblib
    ├── tfidf_matrix.npz
    ├── als_user_factors.npy
    ├── als_item_factors.npy
    └── id_mapping.pkl
```

The `artifacts` directory is created by `train.py` and is loaded by `app.py` at startup. [file:1][file:3]

---

### Data Requirements [file:3]

- `books.csv`: contains the book catalog with at least `book_id`, `title`, `image_url`, `authors`, `original_publication_year`, and `language_code`. [file:3]  
- `ratings.csv`: contains user feedback with at least `user_id`, `book_id`, and a numeric `rating`. [file:3]  
- During training, ratings are filtered so that only `book_id`s present in `books.csv` are kept, ensuring consistency between the catalog and the interaction data. [file:3]

---

### Installation [file:1][file:3]

1. Create and activate a Python 3 virtual environment. [file:1][file:3]  
2. Install dependencies: [file:1][file:3]  

   ```
   pip install flask numpy pandas scipy scikit-learn implicit joblib
   ```

3. Place `books.csv` and `ratings.csv` in the project root directory. [file:3]

---

### Training Pipeline (`train.py`) [file:3]

The training script is responsible for preparing all artifacts required by the web app. [file:3]  

Main steps: [file:3]  

1. **Load and filter data**: read `books.csv` and `ratings.csv`, then keep only ratings whose `book_id` exists in the book catalog. [file:3]  
2. **TF-IDF features**: fit a `TfidfVectorizer(stop_words="english")` on `books["title"].fillna("")` and build the sparse `tfidf_matrix`. [file:3]  
3. **ALS model**: construct a user–item CSR matrix from ratings and train an implicit ALS model on that matrix to get `als.user_factors` and `als.item_factors`. [file:3]  
4. **ID mappings**: build dictionaries mapping between raw IDs and matrix indices (`user_id_to_code`, `book_id_to_code`, `code_to_book_id`). [file:3]  
5. **Export artifacts** to the `artifacts/` folder: [file:3]  

   - Cleaned `artifacts/books.csv` with aligned columns. [file:3]  
   - `artifacts/tfidf_vectorizer.joblib` and `artifacts/tfidf_matrix.npz`. [file:3]  
   - `artifacts/als_user_factors.npy` and `artifacts/als_item_factors.npy`. [file:3]  
   - `artifacts/id_mapping.pkl` containing the ID mapping dictionaries. [file:3]  

Run the training step with: [file:3]  

```
python train.py
```

---

### Web Application (`app.py`) [file:1]

On startup, the Flask app loads the book catalog, TF-IDF artifacts, ALS factor matrices, and ID mappings from the `artifacts` directory. [file:1]  

Key functions: [file:1]  

- `search_by_keyword(q, topn)`: TF-IDF keyword search over all titles, returning the top matches and their scores. [file:1]  
- `content_neighbors(book_title, topn)`: finds the most similar books to a given title using cosine similarity in TF-IDF space. [file:1]  
- `collaborative_recommend(user_id, topn)`: computes scores via the dot product between ALS user and item factors and returns the top books. [file:1]  
- `hybrid_mmr(user_id, book_title, topn, alpha, lambda_div, disliked)`: fuses content and collaborative scores, filters out disliked books, and applies MMR-based re-ranking for diversity. [file:1]

The app also includes a safeguard that checks the shapes of ALS factor matrices against mapping sizes and swaps them if training accidentally used a transposed matrix. [file:1]

---

### Routes and UI [file:1]

- `GET /`: renders `index.html`, providing: [file:1]  
  - A dropdown of seed titles built from the books catalog. [file:1]  
  - A list or range of available `user_id`s derived from `user_id_to_code`. [file:1]  
  - Current dislike list retrieved from session, rendered as books with their titles. [file:1]  

- `POST /ui_recommend`: handles the recommendation form submission. [file:1]  
  - `filter_type` chooses between `content`, `collaborative`, and `hybrid` modes. [file:1]  
  - `user_id` can be a specific ID or the special value `"auto"` to randomly pick one from known users. [file:1]  
  - `topn`, `alpha`, and `lambda_div` control the number of results and hybrid/MMR behaviour. [file:1]  
  - Renders `results.html` with metadata such as method, user, seed title, and the list of recommended books. [file:1]  

- `POST /dislike`, `/remove_disliked`, `/clear_disliked`: manage the dislike list stored in the session so users can hide books they are not interested in. [file:1]

---

### Running the App [file:1]

After generating artifacts with `train.py`, start the web server with: [file:1]  

```
python app.py
```

By default, the app runs in debug mode on `0.0.0.0:7001`, making the web UI accessible from a browser pointing to that host and port. [file:1]

---

### Configuration Notes [file:1][file:3]

- The secret key in `app.py` (`app.secret_key`) should be replaced with a strong random value before deploying. [file:1]  
- ALS hyperparameters (factors, regularization, iterations) and TF-IDF options can be tuned directly in `train.py`. [file:3]  
- `topn`, `alpha`, and `lambda_div` are exposed via the UI so that users can experiment with list length, hybrid weighting, and the trade-off between relevance and diversity. [file:1]
```
